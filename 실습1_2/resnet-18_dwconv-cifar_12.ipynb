{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OFcPBY7gxCsi0o27CAarlyggD7N42lu9","timestamp":1698061340102}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **1. 가상환경 설정 및 라이브러리 불러오기**"],"metadata":{"id":"iAiGIre6n2qT"}},{"cell_type":"code","metadata":{"id":"mgcUBh4YExcY","executionInfo":{"status":"ok","timestamp":1699839401585,"user_tz":-540,"elapsed":11533,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d7c56d4-4dbb-485f-aac6-42f6121cd726"},"source":["import os\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import random_split\n","\n","!pip install ptflops\n","from ptflops import get_model_complexity_info\n","\n","try:\n","    from torch.hub import load_state_dict_from_url\n","except ImportError:\n","    from torch.utils.model_zoo import load_url as load_state_dict_from_url"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ptflops\n","  Downloading ptflops-0.7.1.2.tar.gz (15 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n","Building wheels for collected packages: ptflops\n","  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ptflops: filename=ptflops-0.7.1.2-py3-none-any.whl size=13214 sha256=cd675412600a64cb4d638821d8fe0fdc456c5f6aeff4feb7ff4b5be16c470931\n","  Stored in directory: /root/.cache/pip/wheels/9d/90/07/20e8c3221349a85d63b319593e1bcbb6e0c995d2e2bcc5d775\n","Successfully built ptflops\n","Installing collected packages: ptflops\n","Successfully installed ptflops-0.7.1.2\n"]}]},{"cell_type":"code","source":["### 구글 드라이브 마운트 ###\n","# 체크포인트 저장을 위함\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3Gyt0Q_K3mk","executionInfo":{"status":"ok","timestamp":1699839432489,"user_tz":-540,"elapsed":22438,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"outputId":"624b019a-9bfd-426b-975b-997057ae3951"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path = './drive/MyDrive/Colab Notebooks/checkpoints/'\n","if not os.path.exists(path):\n","  os.makedirs(path)"],"metadata":{"id":"U7hCTnTjy9V3","executionInfo":{"status":"ok","timestamp":1699839432489,"user_tz":-540,"elapsed":2,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# GPU로 연산.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 랜덤 시드 고정.\n","# 실험 조건을 동일하게 설정하여,\n","# 같은 input을 넣으면 같은 결과가 나올 수 있도록 함.\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"metadata":{"id":"Osew3wfeYoYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Dataset 불러오기 (CIFAR10)"],"metadata":{"id":"_jLT6P8GUE08"}},{"cell_type":"code","metadata":{"id":"7woqU9-ZF8CV","executionInfo":{"status":"ok","timestamp":1699839442640,"user_tz":-540,"elapsed":10152,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"outputId":"586ae239-c1ed-4d93-8a1b-8b80f1c24e74","colab":{"base_uri":"https://localhost:8080/"}},"source":["# load the data\n","train_transform = transforms.Compose(\n","    [\n","     transforms.RandomCrop(32, padding=4),\n","     transforms.RandomHorizontalFlip(),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784))])\n","\n","test_transform = transforms.Compose(\n","    [\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784))])\n","\n","ds = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","\n","\n","test_ds = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=test_transform)\n","\n","# split the training set and validation set\n","torch.manual_seed(50)\n","test_size = len(test_ds)\n","val_size = 5000\n","train_size = len(ds) - val_size\n","batch_size = 256\n","\n","train_ds, val_ds = random_split(ds, [train_size, val_size])\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n","\n","val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","classes = ds.classes\n","\n","print(train_size)\n","print(val_size)\n","print(test_size)\n","print(torch.cuda.is_available())"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 29734232.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","45000\n","5000\n","10000\n","True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"markdown","source":["# 3. 네트워크 설계 (ResNet18 model)\n","\n","*   flops와 parameter 분석\n","\n"],"metadata":{"id":"oz8NU1Vb8VUG"}},{"cell_type":"code","source":["### original model ###\n","\n","__all__ = ['ResNet', 'resnet18']\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError(\n","                'BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\n","                \"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n","    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n","    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n","    # This variant is also known as ResNet V1.5 and improves accuracy according to\n","    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n","\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(\n","                    m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        # See note [TorchScript super()]\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n","def resnet_18_cifar():\n","    r\"\"\"\n","        Modify the resnet 18 network in order to run on cifar-10 dataset\n","\n","        To enhance the accuracy, the (kernel_size, stride, padding) of conv1 is modified to (3, 1, 1)\n","        referenced by <https://github.com/akamaster/pytorch_resnet_cifar10>\n","    \"\"\"\n","    model = ResNet(block=BasicBlock, layers=[2, 2, 2, 2], num_classes=10)\n","    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n","                            bias=False)\n","\n","    return model"],"metadata":{"id":"8XSSmFIZORJ0","executionInfo":{"status":"ok","timestamp":1699840352552,"user_tz":-540,"elapsed":442,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["net = resnet_18_cifar()\n","macs, params = get_model_complexity_info(net, (3, 32, 32), as_strings=True,\n","                                           print_per_layer_stat=True, verbose=True)\n","print(macs,'macs')\n","print(params,'params')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEMmlMB8NALZ","executionInfo":{"status":"ok","timestamp":1699840372233,"user_tz":-540,"elapsed":495,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"outputId":"f7dfa7f5-0a87-4cd8-b7aa-126d4c3d7c4e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: module BasicBlock is treated as a zero-op.\n","Warning: module ResNet is treated as a zero-op.\n","ResNet(\n","  11.17 M, 100.000% Params, 140.85 MMac, 99.819% MACs, \n","  (conv1): Conv2d(1.73 k, 0.015% Params, 1.77 MMac, 1.254% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(128, 0.001% Params, 131.07 KMac, 0.093% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.046% MACs, inplace=True)\n","  (maxpool): MaxPool2d(0, 0.000% Params, 65.54 KMac, 0.046% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    147.97 k, 1.324% Params, 37.95 MMac, 26.892% MACs, \n","    (0): BasicBlock(\n","      73.98 k, 0.662% Params, 18.97 MMac, 13.446% MACs, \n","      (conv1): Conv2d(36.86 k, 0.330% Params, 9.44 MMac, 6.688% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, 0.001% Params, 32.77 KMac, 0.023% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 32.77 KMac, 0.023% MACs, inplace=True)\n","      (conv2): Conv2d(36.86 k, 0.330% Params, 9.44 MMac, 6.688% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, 0.001% Params, 32.77 KMac, 0.023% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      73.98 k, 0.662% Params, 18.97 MMac, 13.446% MACs, \n","      (conv1): Conv2d(36.86 k, 0.330% Params, 9.44 MMac, 6.688% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, 0.001% Params, 32.77 KMac, 0.023% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 32.77 KMac, 0.023% MACs, inplace=True)\n","      (conv2): Conv2d(36.86 k, 0.330% Params, 9.44 MMac, 6.688% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, 0.001% Params, 32.77 KMac, 0.023% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    525.57 k, 4.704% Params, 33.67 MMac, 23.861% MACs, \n","    (0): BasicBlock(\n","      230.14 k, 2.060% Params, 14.75 MMac, 10.450% MACs, \n","      (conv1): Conv2d(73.73 k, 0.660% Params, 4.72 MMac, 3.344% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, 0.002% Params, 16.38 KMac, 0.012% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 16.38 KMac, 0.012% MACs, inplace=True)\n","      (conv2): Conv2d(147.46 k, 1.320% Params, 9.44 MMac, 6.688% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, 0.002% Params, 16.38 KMac, 0.012% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        8.45 k, 0.076% Params, 540.67 KMac, 0.383% MACs, \n","        (0): Conv2d(8.19 k, 0.073% Params, 524.29 KMac, 0.372% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, 0.002% Params, 16.38 KMac, 0.012% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      295.42 k, 2.644% Params, 18.92 MMac, 13.411% MACs, \n","      (conv1): Conv2d(147.46 k, 1.320% Params, 9.44 MMac, 6.688% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, 0.002% Params, 16.38 KMac, 0.012% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 16.38 KMac, 0.012% MACs, inplace=True)\n","      (conv2): Conv2d(147.46 k, 1.320% Params, 9.44 MMac, 6.688% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, 0.002% Params, 16.38 KMac, 0.012% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    2.1 M, 18.791% Params, 33.61 MMac, 23.821% MACs, \n","    (0): BasicBlock(\n","      919.04 k, 8.225% Params, 14.71 MMac, 10.427% MACs, \n","      (conv1): Conv2d(294.91 k, 2.639% Params, 4.72 MMac, 3.344% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, 0.005% Params, 8.19 KMac, 0.006% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 8.19 KMac, 0.006% MACs, inplace=True)\n","      (conv2): Conv2d(589.82 k, 5.279% Params, 9.44 MMac, 6.688% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, 0.005% Params, 8.19 KMac, 0.006% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        33.28 k, 0.298% Params, 532.48 KMac, 0.377% MACs, \n","        (0): Conv2d(32.77 k, 0.293% Params, 524.29 KMac, 0.372% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, 0.005% Params, 8.19 KMac, 0.006% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      1.18 M, 10.566% Params, 18.9 MMac, 13.394% MACs, \n","      (conv1): Conv2d(589.82 k, 5.279% Params, 9.44 MMac, 6.688% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, 0.005% Params, 8.19 KMac, 0.006% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 8.19 KMac, 0.006% MACs, inplace=True)\n","      (conv2): Conv2d(589.82 k, 5.279% Params, 9.44 MMac, 6.688% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, 0.005% Params, 8.19 KMac, 0.006% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    8.39 M, 75.119% Params, 33.58 MMac, 23.800% MACs, \n","    (0): BasicBlock(\n","      3.67 M, 32.872% Params, 14.7 MMac, 10.415% MACs, \n","      (conv1): Conv2d(1.18 M, 10.557% Params, 4.72 MMac, 3.344% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1.02 k, 0.009% Params, 4.1 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 4.1 KMac, 0.003% MACs, inplace=True)\n","      (conv2): Conv2d(2.36 M, 21.114% Params, 9.44 MMac, 6.688% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(1.02 k, 0.009% Params, 4.1 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        132.1 k, 1.182% Params, 528.38 KMac, 0.374% MACs, \n","        (0): Conv2d(131.07 k, 1.173% Params, 524.29 KMac, 0.372% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1.02 k, 0.009% Params, 4.1 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      4.72 M, 42.247% Params, 18.89 MMac, 13.385% MACs, \n","      (conv1): Conv2d(2.36 M, 21.114% Params, 9.44 MMac, 6.688% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1.02 k, 0.009% Params, 4.1 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 4.1 KMac, 0.003% MACs, inplace=True)\n","      (conv2): Conv2d(2.36 M, 21.114% Params, 9.44 MMac, 6.688% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(1.02 k, 0.009% Params, 4.1 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 2.05 KMac, 0.001% MACs, output_size=(1, 1))\n","  (fc): Linear(5.13 k, 0.046% Params, 5.13 KMac, 0.004% MACs, in_features=512, out_features=10, bias=True)\n",")\n","141.1 MMac macs\n","11.17 M params\n"]}]},{"cell_type":"markdown","source":["# 4. 학습 진행\n","\n","\n","*   학습 진행을 위한 함수 (validate, train, test 함수)\n","*   학습 진행\n","\n","\n","\n","\n"],"metadata":{"id":"00mRnHXyU4ER"}},{"cell_type":"code","metadata":{"id":"T5dB4kF7Gdva","executionInfo":{"status":"ok","timestamp":1699840376752,"user_tz":-540,"elapsed":440,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}}},"source":["import time\n","\n","def validate(model, criterion, val_loader, use_gpu=False):\n","  val_size = len(val_loader.dataset)\n","  val_loss = 0\n","  correct = 0\n","  device = torch.device( \"cuda:0\" if use_gpu else \"cpu\" )\n","\n","  with torch.no_grad():\n","    for i, data in enumerate(val_loader):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs).to(device)\n","        loss = criterion(outputs, labels)\n","\n","        val_loss += loss * inputs.size(0)\n","\n","        # val accuracy\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct += (predicted == labels).sum().item()\n","\n","    val_loss = val_loss/val_size\n","    val_accuracy = correct/val_size;\n","\n","  return val_loss, val_accuracy\n","\n","def get_train_accuracy(model, criterion, train_loader, use_gpu=False):\n","   train_size = len(train_loader.dataset)\n","   correct = 0\n","   device = torch.device( \"cuda:0\" if use_gpu else \"cpu\" )\n","\n","   with torch.no_grad():\n","    for i, data in enumerate(train_loader):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs).to(device)\n","\n","        # val accuracy\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct += (predicted == labels).sum().item()\n","\n","    print(correct)\n","    return correct/train_size\n","\n","def train(model, criterion, optimizer, train_loader, val_loader, path_name, epoch=2, use_gpu=False):\n","  best_loss = 999999\n","  train_size = len(train_loader.dataset)\n","  device = torch.device( \"cuda:0\" if use_gpu else \"cpu\" )\n","\n","  history = {\n","      'train_loss': [],\n","      'train_accuracy': [],\n","      'val_loss': [],\n","      'val_accuracy': []\n","      }\n","\n","  model = model.to(device)\n","\n","  for epoch in range(epoch):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    correct = 0\n","\n","    print(f'------------------------------\\n Epoch: {epoch + 1}')\n","\n","    t1 = time.time()\n","    for  i,data in enumerate(train_loader):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # as loss.item() return the average batch loss, so convert it to the total loss\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    t2 = time.time()\n","    t = t2 - t1\n","\n","    # save the model\n","    PATH = './drive/My Drive/Colab Notebooks/checkpoints/'\n","\n","    if loss < best_loss:\n","      best_loss = loss\n","      torch.save(model.state_dict(), os.path.join(PATH, path_name))\n","    epoch_train_loss = running_loss/train_size\n","    epoch_train_accuracy = get_train_accuracy(model, criterion, train_loader, use_gpu)\n","    epoch_val_loss, epoch_val_accuracy = validate(model, criterion, val_loader, use_gpu)\n","    print(f'time: {int(t)}sec train_loss: {epoch_train_loss}, train_accuracy: {epoch_train_accuracy}, val_loss: {epoch_val_loss}, val_accuracy: {epoch_val_accuracy}');\n","\n","    history['train_loss'].append(epoch_train_loss)\n","    history['train_accuracy'].append(epoch_train_accuracy)\n","    history['val_loss'].append(epoch_val_loss)\n","    history['val_accuracy'].append(epoch_val_accuracy)\n","\n","  return history"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCBeSMOeGiAT","outputId":"012a6e95-bab5-4271-a800-1ccce1ad5adc","colab":{"base_uri":"https://localhost:8080/"}},"source":["# define a model\n","model = resnet_18_cifar()\n","# 학습을 위한 하이퍼파라미터\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","\n","# save the model\n","path_name = 'original_best.pth'\n","# 학습\n","history = train(model, criterion, optimizer, train_loader, val_loader, path_name, 10, torch.cuda.is_available())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------\n"," Epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["23079\n","time: 22sec train_loss: 1.635821014934116, train_accuracy: 0.5128666666666667, val_loss: 1.3223981857299805, val_accuracy: 0.5148\n","------------------------------\n"," Epoch: 2\n"]}]},{"cell_type":"markdown","source":["#5. test set에 대한 성능 측정\n"],"metadata":{"id":"ZQSYrm9lVlcQ"}},{"cell_type":"code","metadata":{"id":"Y9abEvxn-r6X","executionInfo":{"status":"ok","timestamp":1699840056266,"user_tz":-540,"elapsed":2,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}}},"source":["# run test set\n","def test(model, criterion, test_loader, use_gpu=False):\n","  test_size = len(test_loader.dataset)\n","  device = torch.device( \"cuda:0\" if use_gpu else \"cpu\" )\n","  test_loss = 0.0\n","  test_accuracy = 0\n","  correct = 0\n","  model.eval()\n","  with torch.no_grad():\n","      for i, data in enumerate(test_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data[0].to(device), data[1].to(device)\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs).to(device)\n","          loss = criterion(outputs, labels)\n","\n","          test_loss += loss * inputs.size(0)\n","\n","          # val accuracy\n","          _, predicted = torch.max(outputs.data, 1)\n","          correct += (predicted == labels).sum().item()\n","\n","\n","      test_loss = test_loss/test_size\n","      test_accuracy = correct/test_size;\n","\n","  return test_loss, test_accuracy"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2euJi6fBJdb","executionInfo":{"status":"ok","timestamp":1699840062008,"user_tz":-540,"elapsed":5743,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}}},"source":["test_loss, test_accuracy = test(model, criterion, test_loader, True)\n","history['test_loss'] = test_loss\n","history['test_accuracy'] = test_accuracy"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NNBClh2BhtN","executionInfo":{"status":"ok","timestamp":1699840062008,"user_tz":-540,"elapsed":5,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"outputId":"20740d16-a9da-406a-b973-2b7396830ce7","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(history['test_loss'], history['test_accuracy'] )"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.6132, device='cuda:0') 0.792\n"]}]},{"cell_type":"markdown","source":["# ResNet18 lightweight model\n","\n","*   convolution layer를 depth-wise separable convolution으로 변환\n","*   flops와 parameter 분석\n","*   ResNet18 lightweight model 학습\n","*   test set에 대해 성능 측정\n","\n","\n","\n","\n"],"metadata":{"id":"qsHe47pi8acf"}},{"cell_type":"code","metadata":{"id":"tip_XdAYFGRK","executionInfo":{"status":"ok","timestamp":1699840062008,"user_tz":-540,"elapsed":4,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}}},"source":["### light_weight model ###\n","\n","__all__ = ['ResNet', 'resnet18']\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=in_planes, bias=False, dilation=dilation)\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError(\n","                'BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\n","                \"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.dwconv33_1 = conv3x3(inplanes, planes, stride)\n","        self.conv11_1 = conv1x1(planes, planes)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.dwconv33_2 = conv3x3(planes, planes)\n","        self.conv11_2 = conv1x1(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.dwconv33_1(x)\n","        out = self.conv11_1(out)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.dwconv33_2(out)\n","        out = self.conv11_2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n","    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n","    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n","    # This variant is also known as ResNet V1.5 and improves accuracy according to\n","    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n","\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(\n","                    m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        # See note [TorchScript super()]\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n","def resnet_18_cifar_lightweight():\n","    r\"\"\"\n","        Modify the resnet 18 network in order to run on cifar-10 dataset\n","\n","        To enhance the accuracy, the (kernel_size, stride, padding) of conv1 is modified to (3, 1, 1)\n","        referenced by <https://github.com/akamaster/pytorch_resnet_cifar10>\n","    \"\"\"\n","    model = ResNet(block=BasicBlock, layers=[2, 2, 2, 2], num_classes=10)\n","\n","    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n","                            bias=False)\n","\n","    return model"],"execution_count":13,"outputs":[]},{"cell_type":"code","source":["net = resnet_18_cifar_lightweight()\n","macs, params = get_model_complexity_info(net, (3, 32, 32), as_strings=True,\n","                                           print_per_layer_stat=True, verbose=True)\n","print(macs,'macs')\n","print(params,'params')"],"metadata":{"id":"mdob4eIk7pGj","executionInfo":{"status":"ok","timestamp":1699840062469,"user_tz":-540,"elapsed":465,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e739d2da-e1e5-4a3e-f79e-a42a6d6f8e51"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: module BasicBlock is treated as a zero-op.\n","Warning: module ResNet is treated as a zero-op.\n","ResNet(\n","  1.62 M, 100.000% Params, 21.89 MMac, 98.844% MACs, \n","  (conv1): Conv2d(1.73 k, 0.107% Params, 1.77 MMac, 7.989% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(128, 0.008% Params, 131.07 KMac, 0.592% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.296% MACs, inplace=True)\n","  (maxpool): MaxPool2d(0, 0.000% Params, 65.54 KMac, 0.296% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    19.2 k, 1.188% Params, 4.98 MMac, 22.488% MACs, \n","    (0): BasicBlock(\n","      9.6 k, 0.594% Params, 2.49 MMac, 11.244% MACs, \n","      (dwconv33_1): Conv2d(576, 0.036% Params, 147.46 KMac, 0.666% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","      (conv11_1): Conv2d(4.1 k, 0.254% Params, 1.05 MMac, 4.734% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, 0.008% Params, 32.77 KMac, 0.148% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 32.77 KMac, 0.148% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(576, 0.036% Params, 147.46 KMac, 0.666% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","      (conv11_2): Conv2d(4.1 k, 0.254% Params, 1.05 MMac, 4.734% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, 0.008% Params, 32.77 KMac, 0.148% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      9.6 k, 0.594% Params, 2.49 MMac, 11.244% MACs, \n","      (dwconv33_1): Conv2d(576, 0.036% Params, 147.46 KMac, 0.666% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","      (conv11_1): Conv2d(4.1 k, 0.254% Params, 1.05 MMac, 4.734% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, 0.008% Params, 32.77 KMac, 0.148% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 32.77 KMac, 0.148% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(576, 0.036% Params, 147.46 KMac, 0.666% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","      (conv11_2): Conv2d(4.1 k, 0.254% Params, 1.05 MMac, 4.734% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, 0.008% Params, 32.77 KMac, 0.148% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    79.62 k, 4.928% Params, 5.13 MMac, 23.154% MACs, \n","    (0): BasicBlock(\n","      44.03 k, 2.725% Params, 2.83 MMac, 12.798% MACs, \n","      (dwconv33_1): Conv2d(1.15 k, 0.071% Params, 73.73 KMac, 0.333% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","      (conv11_1): Conv2d(16.38 k, 1.014% Params, 1.05 MMac, 4.734% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, 0.016% Params, 16.38 KMac, 0.074% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 16.38 KMac, 0.074% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(1.15 k, 0.071% Params, 73.73 KMac, 0.333% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","      (conv11_2): Conv2d(16.38 k, 1.014% Params, 1.05 MMac, 4.734% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, 0.016% Params, 16.38 KMac, 0.074% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        8.45 k, 0.523% Params, 540.67 KMac, 2.441% MACs, \n","        (0): Conv2d(8.19 k, 0.507% Params, 524.29 KMac, 2.367% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, 0.016% Params, 16.38 KMac, 0.074% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      35.58 k, 2.202% Params, 2.29 MMac, 10.356% MACs, \n","      (dwconv33_1): Conv2d(1.15 k, 0.071% Params, 73.73 KMac, 0.333% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","      (conv11_1): Conv2d(16.38 k, 1.014% Params, 1.05 MMac, 4.734% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, 0.016% Params, 16.38 KMac, 0.074% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 16.38 KMac, 0.074% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(1.15 k, 0.071% Params, 73.73 KMac, 0.333% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","      (conv11_2): Conv2d(16.38 k, 1.014% Params, 1.05 MMac, 4.734% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, 0.016% Params, 16.38 KMac, 0.074% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    306.69 k, 18.982% Params, 4.92 MMac, 22.229% MACs, \n","    (0): BasicBlock(\n","      169.98 k, 10.521% Params, 2.73 MMac, 12.317% MACs, \n","      (dwconv33_1): Conv2d(2.3 k, 0.143% Params, 36.86 KMac, 0.166% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n","      (conv11_1): Conv2d(65.54 k, 4.056% Params, 1.05 MMac, 4.734% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, 0.032% Params, 8.19 KMac, 0.037% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 8.19 KMac, 0.037% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(2.3 k, 0.143% Params, 36.86 KMac, 0.166% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","      (conv11_2): Conv2d(65.54 k, 4.056% Params, 1.05 MMac, 4.734% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, 0.032% Params, 8.19 KMac, 0.037% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        33.28 k, 2.060% Params, 532.48 KMac, 2.404% MACs, \n","        (0): Conv2d(32.77 k, 2.028% Params, 524.29 KMac, 2.367% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, 0.032% Params, 8.19 KMac, 0.037% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      136.7 k, 8.461% Params, 2.2 MMac, 9.913% MACs, \n","      (dwconv33_1): Conv2d(2.3 k, 0.143% Params, 36.86 KMac, 0.166% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","      (conv11_1): Conv2d(65.54 k, 4.056% Params, 1.05 MMac, 4.734% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, 0.032% Params, 8.19 KMac, 0.037% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 8.19 KMac, 0.037% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(2.3 k, 0.143% Params, 36.86 KMac, 0.166% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","      (conv11_2): Conv2d(65.54 k, 4.056% Params, 1.05 MMac, 4.734% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, 0.032% Params, 8.19 KMac, 0.037% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    1.2 M, 74.470% Params, 4.82 MMac, 21.767% MACs, \n","    (0): BasicBlock(\n","      667.65 k, 41.323% Params, 2.67 MMac, 12.076% MACs, \n","      (dwconv33_1): Conv2d(4.61 k, 0.285% Params, 18.43 KMac, 0.083% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n","      (conv11_1): Conv2d(262.14 k, 16.225% Params, 1.05 MMac, 4.734% MACs, 512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1.02 k, 0.063% Params, 4.1 KMac, 0.018% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 4.1 KMac, 0.018% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(4.61 k, 0.285% Params, 18.43 KMac, 0.083% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","      (conv11_2): Conv2d(262.14 k, 16.225% Params, 1.05 MMac, 4.734% MACs, 512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(1.02 k, 0.063% Params, 4.1 KMac, 0.018% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        132.1 k, 8.176% Params, 528.38 KMac, 2.386% MACs, \n","        (0): Conv2d(131.07 k, 8.112% Params, 524.29 KMac, 2.367% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1.02 k, 0.063% Params, 4.1 KMac, 0.018% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      535.55 k, 33.147% Params, 2.15 MMac, 9.691% MACs, \n","      (dwconv33_1): Conv2d(4.61 k, 0.285% Params, 18.43 KMac, 0.083% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","      (conv11_1): Conv2d(262.14 k, 16.225% Params, 1.05 MMac, 4.734% MACs, 512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1.02 k, 0.063% Params, 4.1 KMac, 0.018% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(0, 0.000% Params, 4.1 KMac, 0.018% MACs, inplace=True)\n","      (dwconv33_2): Conv2d(4.61 k, 0.285% Params, 18.43 KMac, 0.083% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","      (conv11_2): Conv2d(262.14 k, 16.225% Params, 1.05 MMac, 4.734% MACs, 512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(1.02 k, 0.063% Params, 4.1 KMac, 0.018% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 2.05 KMac, 0.009% MACs, output_size=(1, 1))\n","  (fc): Linear(5.13 k, 0.318% Params, 5.13 KMac, 0.023% MACs, in_features=512, out_features=10, bias=True)\n",")\n","22.15 MMac macs\n","1.62 M params\n"]}]},{"cell_type":"code","source":["# define a model\n","model = resnet_18_cifar_lightweight()\n","# 학습을 위한 하이퍼파라미터\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","\n","# save the model\n","path_name = 'lightweight_best.pth'\n","# 학습\n","history = train(model, criterion, optimizer, train_loader, val_loader, path_name, 10, torch.cuda.is_available())"],"metadata":{"id":"H2TBg4j7WseF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loss, test_accuracy = test(model, criterion, test_loader, True)\n","history['test_loss'] = test_loss\n","history['test_accuracy'] = test_accuracy"],"metadata":{"id":"KlkptD2gWuLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(history['test_loss'], history['test_accuracy'] )"],"metadata":{"id":"oxx9R4u6WvL_"},"execution_count":null,"outputs":[]}]}