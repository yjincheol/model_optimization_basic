{"cells":[{"cell_type":"markdown","metadata":{"id":"pyd5BeM0Cdmv"},"source":["# PTQ basic experiments\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXBNaQW4Yt5g"},"outputs":[],"source":["# Basic imports\n","import time\n","from enum import Enum\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"iuZi6OS9hedU"},"source":["## Arguments\n","\n","### argument options\n","*   bitW : choose weight parameter bits\n","*   bitA : choose activation parameter bits\n","*   per_ch : granularity option (if per_ch is True, Channelwise Quantization else Layerwise Quantization)\n","*   symW : choose symmetric quantization or asymmetric quantization about weight parameter\n","*   symA : choose symmetric quantization or asymmetric quantization about activation map parameter\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699763126936,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"},"user_tz":-540},"id":"Kq5EIwHWcc6B","outputId":"5e008d4f-df55-4860-c9b8-7978c5226275"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on GPU\n"]}],"source":["import easydict\n","args = easydict.EasyDict({\n","    \"workers\" : 4,\n","    \"batch_size\" : 128,\n","    \"print_freq\" : 10,\n","    \"bitW\" : 4,     # 1~k bit(2 ~ 8 bit recommended)\n","    \"bitA\" : 4,     # 1~k bit(2 ~ 8 bit recommended)\n","    \"symW\" : True,\n","    \"per_ch\" : False,\n","    \"symA\" : False,\n","})\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print('Training on GPU')\n","else:\n","  device = torch.device(\"cpu\")\n","  print('Training on CPU')\n"]},{"cell_type":"markdown","metadata":{"id":"LkKyfZbsk9jP"},"source":["## Functions\n","\n","\n","*   Functions for accuracy\n","*   Prepare datasets about CIFAR10\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNy8HEjRdg_E"},"outputs":[],"source":["# define loss function (criterion)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7prPn9pgYUu"},"outputs":[],"source":["class Summary(Enum):\n","  NONE = 0\n","  AVERAGE = 1\n","  SUM = 2\n","  COUNT = 3\n","\n","class AverageMeter(object):\n","  \"\"\"Computes and stores the average and current value\"\"\"\n","  def __init__(self, name, fmt=':f', summary_type=Summary.AVERAGE):\n","      self.name = name\n","      self.fmt = fmt\n","      self.summary_type = summary_type\n","      self.reset()\n","\n","  def reset(self):\n","      self.val = 0\n","      self.avg = 0\n","      self.sum = 0\n","      self.count = 0\n","\n","  def update(self, val, n=1):\n","      self.val = val\n","      self.sum += val * n\n","      self.count += n\n","      self.avg = self.sum / self.count\n","\n","  def all_reduce(self):\n","      if torch.cuda.is_available():\n","          device = torch.device(\"cuda\")\n","      else:\n","          device = torch.device(\"cpu\")\n","      total = torch.tensor([self.sum, self.count], dtype=torch.float32, device=device)\n","      self.sum, self.count = total.tolist()\n","      self.avg = self.sum / self.count\n","\n","  def __str__(self):\n","      fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","      return fmtstr.format(**self.__dict__)\n","\n","  def summary(self):\n","      fmtstr = ''\n","      if self.summary_type is Summary.NONE:\n","          fmtstr = ''\n","      elif self.summary_type is Summary.AVERAGE:\n","          fmtstr = '{name} {avg:.3f}'\n","      elif self.summary_type is Summary.SUM:\n","          fmtstr = '{name} {sum:.3f}'\n","      elif self.summary_type is Summary.COUNT:\n","          fmtstr = '{name} {count:.3f}'\n","      else:\n","          raise ValueError('invalid summary type %r' % self.summary_type)\n","\n","      return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","  def __init__(self, num_batches, meters, prefix=\"\"):\n","      self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","      self.meters = meters\n","      self.prefix = prefix\n","\n","  def display(self, batch):\n","      entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","      entries += [str(meter) for meter in self.meters]\n","      print('\\t'.join(entries))\n","\n","  def display_summary(self):\n","      entries = [\" *\"]\n","      entries += [meter.summary() for meter in self.meters]\n","      print(' '.join(entries))\n","\n","  def _get_batch_fmtstr(self, num_batches):\n","      num_digits = len(str(num_batches // 1))\n","      fmt = '{:' + str(num_digits) + 'd}'\n","      return '[' + fmt + '/' + fmt.format(num_batches) + ']'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dViJJIdHfD0j"},"outputs":[],"source":["def make_dataloaders(args):\n","    train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n","                                          transforms.RandomHorizontalFlip(),\n","                                          transforms.ToTensor(),\n","                                          transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n","\n","    valid_transform = transforms.Compose([transforms.ToTensor(),\n","                                               transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n","\n","    #transform_validation = transforms.Compose([transforms.ToTensor()])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='./train', train=True, download=True, transform=train_transform)\n","    testset = torchvision.datasets.CIFAR10(root='./val', train=False, download=True, transform=valid_transform)\n","\n","    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers)\n","    val_loader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n","\n","    print(\"number of training dataset:%d\"%len(trainset))\n","    print(\"number of validation dataset:%d\"%len(testset))\n","    return train_loader, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PHa2GNggKyJ"},"outputs":[],"source":["def validate(val_loader, model, criterion):\n","\n","  def run_validate(loader, base_progress=0):\n","      with torch.no_grad():\n","          end = time.time()\n","          for i, (images, target) in enumerate(loader):\n","              i = base_progress + i\n","              if torch.cuda.is_available():\n","                  images, target = images.cuda(), target.cuda()\n","\n","              # compute output\n","              output = model(images)\n","              loss = criterion(output, target)\n","\n","              # measure accuracy and record loss\n","              acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","              losses.update(loss.item(), images.size(0))\n","              top1.update(acc1[0], images.size(0))\n","              top5.update(acc5[0], images.size(0))\n","\n","              # measure elapsed time\n","              batch_time.update(time.time() - end)\n","              end = time.time()\n","\n","              if i % args.print_freq == 0:\n","                  progress.display(i + 1)\n","\n","  batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)\n","  losses = AverageMeter('Loss', ':.4e', Summary.NONE)\n","  top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)\n","  top5 = AverageMeter('Acc@5', ':6.2f', Summary.AVERAGE)\n","  progress = ProgressMeter(\n","      len(val_loader),[batch_time, losses, top1, top5],prefix='Test: ')\n","\n","  # switch to evaluate mode\n","  model.eval()\n","\n","  run_validate(val_loader)\n","\n","  progress.display_summary()\n","\n","  return top1.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOaZo83fCcIH"},"outputs":[],"source":["def accuracy(output, target, topk=(1,)):\n","  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n","  with torch.no_grad():\n","      maxk = max(topk)\n","      batch_size = target.size(0)\n","\n","      _, pred = output.topk(maxk, 1, True, True)\n","      pred = pred.t()\n","      correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","      res = []\n","      for k in topk:\n","          correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","          res.append(correct_k.mul_(100.0 / batch_size))\n","      return res"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36383,"status":"ok","timestamp":1699763294933,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"},"user_tz":-540},"id":"8bxgKj8ijt26","outputId":"413bc2ee-2f3f-4184-e194-fa74a3c1fcca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:12<00:00, 13604586.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./train/cifar-10-python.tar.gz to ./train\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./val/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:12<00:00, 13336313.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./val/cifar-10-python.tar.gz to ./val\n","number of training dataset:50000\n","number of validation dataset:10000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_loader, val_loader = make_dataloaders(args)"]},{"cell_type":"markdown","metadata":{"id":"hwhpuoOOlezs"},"source":["## Functions for quantization\n","\n","\n","*   calcScaleZeroPoint : Asymmetric quantization mode\n","*   quantize_weight : Weight quantization mode(symmetry or asymmetry)\n","*   quantize_activation : Activation map quantization mode(only asymmetry)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2ccIKIJo-RH"},"outputs":[],"source":["def calcScaleZeroPoint(min_val, max_val, num_bits):\n","    qmin = 0.\n","    qmax = 2. ** num_bits - 1.\n","    scale = (max_val - min_val) / (qmax - qmin)\n","\n","    zero_point = qmax - max_val / scale\n","\n","    if zero_point < qmin:\n","        zero_point = torch.tensor([qmin], dtype=torch.float32).to(min_val.device)\n","    elif zero_point > qmax:\n","        zero_point = torch.tensor([qmax], dtype=torch.float32).to(max_val.device)\n","\n","    zero_point.round_()\n","\n","    return scale, zero_point\n","\n","def quantize_weight(x, args):\n","  bits = args.bitW\n","  q_x = torch.empty_like(x).copy_(x)\n","  dq_x = torch.empty_like(x).copy_(x)\n","  if args.symW:\n","    qmin = -2**(bits-1)\n","    qmax = 2**(bits-1)-1\n","    if args.per_ch:\n","      for i in range(len(x)):\n","        scale = (torch.max(x[i,...]) - torch.min(x[i,...])) / (qmax - qmin)\n","        q_x[i,...] = (x[i,...]/scale).round_()\n","        q_x[i,...].clamp(qmin, qmax)\n","        # dequantize\n","        dq_x[i,...] = q_x[i,...]*scale\n","    else:\n","      scale = (torch.max(x) - torch.min(x)) / (qmax - qmin)\n","      q_x = (x/scale).round_()\n","      q_x.clamp(qmin, qmax)\n","      # dequantize\n","      dq_x = q_x * scale\n","  else:\n","    qmin = 0\n","    qmax = 2**(bits)-1\n","    scale, zero_point = calcScaleZeroPoint(torch.min(x),torch.max(x),bits)\n","    q_x = (x/scale).round_() - zero_point\n","    q_x.clamp(qmin, qmax)\n","    # dequantize\n","    dq_x = (q_x+ zero_point)* scale\n","  return dq_x, scale\n","\n","def quantize_activation(x, bits):\n","  q_x = torch.empty_like(x).copy_(x)\n","  dq_x = torch.empty_like(x).copy_(x)\n","  qmin = 0\n","  qmax = 2**(bits)-1\n","  scale, zero_point = calcScaleZeroPoint(torch.min(x),torch.max(x),bits)\n","  q_x = (x/scale).round_() - zero_point\n","  q_x.clamp(qmin, qmax)\n","  # dequantize\n","  dq_x = (q_x+ zero_point)* scale\n","  return dq_x"]},{"cell_type":"markdown","metadata":{"id":"NqKru0RRm8o2"},"source":["## Layer for Quantization\n","\n","\n","*   QConv2d : Quantization for Conv2d layer weight values  \n","*   QLinear : Quantization for Linear layer weight values  \n","*   QReLU : Quantization for ReLU activation function   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G4lqSyJTgJeu"},"outputs":[],"source":["class QConv2d(nn.Conv2d):\n","  def __init__(self, in_channels, out_channels, args, kernel_size, stride=1,padding=0, dilation=1, groups=1, bias=False):\n","    super(QConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n","    self.args = args\n","    self.k = args.bitW\n","\n","  def forward(self, input):\n","    if self.k != 32:\n","      quantized_weight, _ = quantize_weight(self.weight, self.args)\n","      if self.bias is not None:\n","          quantized_bias = self.bias\n","      else:\n","          quantized_bias = None\n","      return F.conv2d(input, quantized_weight, quantized_bias, self.stride, self.padding, self.dilation, self.groups)\n","    else:\n","      return F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrSsPda0mJOY"},"outputs":[],"source":["class QLinear(nn.Linear):\n","  def __init__(self, in_features, out_features, args, bias=False):\n","    super(QLinear, self).__init__(in_features=in_features, out_features=out_features, bias=bias)\n","    self.args = args\n","    self.k = args.bitW\n","\n","  def forward(self, input):\n","    if self.k != 32:\n","      quantized_weight, _ = quantize_weight(self.weight, self.args)\n","\n","      if self.bias is not None:\n","          quantized_bias = self.bias\n","      else:\n","          quantized_bias = None\n","\n","      return F.linear(input, quantized_weight, quantized_bias)\n","    else:\n","      return F.linear(input, self.weight, self.bias)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooCFDTjLnpU9"},"outputs":[],"source":["class QReLU(nn.ReLU):\n","  def __init__(self, bitA, inplace=False):\n","    super(QReLU, self).__init__(inplace=inplace)\n","    self.k = bitA\n","\n","  def forward(self, input):\n","    out = F.relu(input)\n","    if self.k != 32:\n","      return quantize_activation(out, self.k)\n","    else:\n","      return out"]},{"cell_type":"markdown","metadata":{"id":"ZrQdm9btqpyz"},"source":["## CIFAR10_ResNet20 model network\n","\n","\n","\n","*   Build pretrained model on cifar10\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WlZQAcrFB4i"},"outputs":[],"source":["import sys\n","import torch.nn as nn\n","try:\n","    from torch.hub import load_state_dict_from_url\n","except ImportError:\n","    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n","\n","from functools import partial\n","from typing import Dict, Type, Any, Callable, Union, List, Optional\n","\n","model_urls = 'https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt'\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, inplanes, planes, args, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = QConv2d(inplanes, planes, args, kernel_size=3, stride=stride,padding=1)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.QReLU = QReLU(args.bitA,inplace=True)\n","        self.conv2 = QConv2d(planes, planes,args,kernel_size=3,padding=1)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.QReLU(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out += identity\n","        out = self.QReLU(out)\n","\n","        return out\n","\n","\n","class CifarResNet(nn.Module):\n","\n","    def __init__(self, block, layers, args, num_classes=10):\n","        super(CifarResNet, self).__init__()\n","        self.inplanes = 16\n","        self.args = args\n","        self.conv1 = QConv2d(3,16, args,kernel_size=3,padding=1)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.QReLU = QReLU(args.bitA, inplace=True)\n","\n","        self.layer1 = self._make_layer(block, 16, layers[0])\n","        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(64 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                QConv2d(self.inplanes, planes * block.expansion, self.args, kernel_size=1, stride = stride),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, self.args, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes,self.args))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.QReLU(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","def _resnet(\n","    arch: str,\n","    layers: List[int],\n","    model_urls: Dict[str, str],\n","    progress: bool = True,\n","    pretrained: bool = True,\n","    **kwargs: Any\n",") -> CifarResNet:\n","    model = CifarResNet(BasicBlock, layers, **kwargs)\n","    if pretrained:\n","        state_dict = load_state_dict_from_url(model_urls, progress=progress)\n","        model.load_state_dict(state_dict)\n","    return model\n","\n","def cifar10_resnet20(*args, **kwargs) -> CifarResNet: pass\n","\n","thismodule = sys.modules[__name__]\n","setattr(thismodule, 'cifar10_resnet20', partial(_resnet, arch=\"resnet20\",layers=[3]*3, model_urls=model_urls, args= args, num_classes=10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gdg6PCuarw9V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699763183853,"user_tz":-540,"elapsed":8956,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"}},"outputId":"3a1029df-120d-44c7-c561-24dfcd924a2d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n","100%|██████████| 1.09M/1.09M [00:01<00:00, 778kB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["CifarResNet(\n","  (conv1): QConv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (QReLU): QReLU(inplace=True)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): QConv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): QConv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): QConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): QConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (QReLU): QReLU(inplace=True)\n","      (conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":15}],"source":["model = cifar10_resnet20()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10556,"status":"ok","timestamp":1699763305480,"user":{"displayName":"양진철전자공학과","userId":"00438325333115314187"},"user_tz":-540},"id":"8X52tCQcZkjV","outputId":"dc0c7b21-0e1d-44cb-b545-a075b5c4fc0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'workers': 4, 'batch_size': 128, 'print_freq': 10, 'bitW': 4, 'bitA': 4, 'symW': True, 'per_ch': False, 'symA': False}\n","Test: [ 1/79]\tTime  8.036 ( 8.036)\tLoss 4.6690e-01 (4.6690e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  99.22 ( 99.22)\n","Test: [11/79]\tTime  0.034 ( 0.769)\tLoss 5.9015e-01 (5.9268e-01)\tAcc@1  82.81 ( 83.95)\tAcc@5  97.66 ( 99.08)\n","Test: [21/79]\tTime  0.030 ( 0.424)\tLoss 5.2312e-01 (5.9590e-01)\tAcc@1  87.50 ( 84.97)\tAcc@5  98.44 ( 98.96)\n","Test: [31/79]\tTime  0.040 ( 0.302)\tLoss 2.7344e-01 (5.8534e-01)\tAcc@1  93.75 ( 85.28)\tAcc@5  99.22 ( 98.92)\n","Test: [41/79]\tTime  0.055 ( 0.238)\tLoss 8.8165e-01 (5.8599e-01)\tAcc@1  80.47 ( 85.23)\tAcc@5  98.44 ( 98.93)\n","Test: [51/79]\tTime  0.076 ( 0.200)\tLoss 5.9611e-01 (5.8055e-01)\tAcc@1  85.16 ( 85.39)\tAcc@5 100.00 ( 99.05)\n","Test: [61/79]\tTime  0.037 ( 0.174)\tLoss 8.3705e-01 (5.8198e-01)\tAcc@1  80.47 ( 85.23)\tAcc@5  99.22 ( 99.08)\n","Test: [71/79]\tTime  0.060 ( 0.157)\tLoss 6.9982e-01 (5.9056e-01)\tAcc@1  84.38 ( 85.13)\tAcc@5  99.22 ( 99.06)\n"," *   Acc@1 85.370 Acc@5 99.080\n","11.478680610656738\n"]}],"source":["print(args)\n","end = time.time()\n","validate(val_loader, model, criterion)\n","print(time.time() - end)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1IY-C01KBGqoFhSz1wSsWyGBnobZEQtd0","timestamp":1698394491495},{"file_id":"11ts5BI6K8_zWPwv3CVTwrblA35_RmTDw","timestamp":1697286524416}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}